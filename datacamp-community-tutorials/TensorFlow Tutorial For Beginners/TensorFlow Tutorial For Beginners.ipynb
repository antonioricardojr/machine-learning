{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Tutorial For Beginners\n",
    "\n",
    "*This notebook was made in preparation for the DataCamp tutorial \"TensorFlow Tutorial for Beginners\"; If you want more explanations on the code or on using TensorFlow, go to the full tutorial [here](https://www.datacamp.com/community/tutorials/tensorflow-tutorial).*\n",
    "\n",
    "The full tutorial covers the following topics:\n",
    "\n",
    "* Introducing Tensors\n",
    "    - Plane Vectors\n",
    "    - Tensors\n",
    "* Installing TensorFlow\n",
    "* [TensorFlow Basics](#basics)\n",
    "* [Loading And Exploring The Data](#exploration)\n",
    "    - Some Statistics\n",
    "    - Visual Exploration\n",
    "* [Feature Extraction](#extraction)\n",
    "    - Rescaling Images\n",
    "    - Image Conversion to Grayscale\n",
    "* [Deep Learning with Tensorflow](#dl)\n",
    "    - Modeling Neural Network\n",
    "    - Running The Neural Network\n",
    "    - Evaluating Your Neural Network\n",
    "* Where To Go Next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DataCamp courses](http://community.datacamp.com.s3.amazonaws.com/community/production/ckeditor_assets/pictures/293/content_blog_banner.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow 1.4.0\n",
      "skimage 0.13.1\n",
      "matplotlib 2.0.0+4144.ge388666\n",
      "numpy 1.13.3\n",
      "random n\u0007\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -p tensorflow,skimage,matplotlib,numpy,random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from skimage import transform\n",
    "from skimage import data\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.color import rgb2gray\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='basics'></a>\n",
    "## TensorFlow Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mul:0\", shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Import `tensorflow`\n",
    "import tensorflow as tf\n",
    "\n",
    "# Initialize two constants\n",
    "x1 = tf.constant([1,2,3,4])\n",
    "x2 = tf.constant([5,6,7,8])\n",
    "\n",
    "# Multiply\n",
    "result = tf.multiply(x1, x2)\n",
    "\n",
    "# Print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 12 21 32]\n"
     ]
    }
   ],
   "source": [
    "# Import `tensorflow` \n",
    "import tensorflow as tf\n",
    "\n",
    "# Initialize two constants\n",
    "x1 = tf.constant([1,2,3,4])\n",
    "x2 = tf.constant([5,6,7,8])\n",
    "\n",
    "# Multiply\n",
    "result = tf.multiply(x1, x2)\n",
    "\n",
    "# Intialize the Session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Print the result\n",
    "print(sess.run(result))\n",
    "\n",
    "# Close the session\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 12 21 32]\n"
     ]
    }
   ],
   "source": [
    "# Import `tensorflow`\n",
    "import tensorflow as tf\n",
    "\n",
    "# Initialize two constants\n",
    "x1 = tf.constant([1,2,3,4])\n",
    "x2 = tf.constant([5,6,7,8])\n",
    "\n",
    "# Multiply\n",
    "result = tf.multiply(x1, x2)\n",
    "\n",
    "# Initialize Session and run `result`\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(result)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exploration'></a>\n",
    "## Loading And Exploring The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    # Get all subdirectories of data_dir. Each represents a label.\n",
    "    directories = [d for d in os.listdir(data_dir) \n",
    "                   if os.path.isdir(os.path.join(data_dir, d))]\n",
    "    # Loop through the label directories and collect the data in\n",
    "    # two lists, labels and images.\n",
    "    labels = []\n",
    "    images = []\n",
    "    for d in directories:\n",
    "        label_dir = os.path.join(data_dir, d)\n",
    "        file_names = [os.path.join(label_dir, f) \n",
    "                      for f in os.listdir(label_dir) \n",
    "                      if f.endswith(\".ppm\")]\n",
    "        for f in file_names:\n",
    "            images.append(data.imread(f))\n",
    "            labels.append(int(d))\n",
    "    return images, labels\n",
    "\n",
    "ROOT_PATH = \"/Users/antonioricardojr/Documents/workspace/machine-learning/datacamp-community-tutorials/TensorFlow Tutorial For Beginners/data\"\n",
    "train_data_dir = os.path.join(ROOT_PATH, \"TrafficSigns/Training\")\n",
    "test_data_dir = os.path.join(ROOT_PATH, \"TrafficSigns/Testing\")\n",
    "\n",
    "images, labels = load_data(train_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4575\n",
      "[[[210 249 232]\n",
      "  [204 249 208]\n",
      "  [197 198 155]\n",
      "  ..., \n",
      "  [ 51  60  40]\n",
      "  [ 54  64  44]\n",
      "  [ 57  66  46]]\n",
      "\n",
      " [[209 250 236]\n",
      "  [212 255 217]\n",
      "  [200 196 156]\n",
      "  ..., \n",
      "  [ 49  57  38]\n",
      "  [ 51  59  41]\n",
      "  [ 53  60  42]]\n",
      "\n",
      " [[203 246 236]\n",
      "  [207 246 213]\n",
      "  [202 192 156]\n",
      "  ..., \n",
      "  [ 47  53  35]\n",
      "  [ 48  54  36]\n",
      "  [ 48  55  37]]\n",
      "\n",
      " ..., \n",
      " [[  2  22  25]\n",
      "  [ 26  56  77]\n",
      "  [ 71 140 159]\n",
      "  ..., \n",
      "  [ 84  77  50]\n",
      "  [ 68  66  41]\n",
      "  [ 56  64  44]]\n",
      "\n",
      " [[  0  22  32]\n",
      "  [ 30  75 106]\n",
      "  [ 87 176 198]\n",
      "  ..., \n",
      "  [ 86  80  52]\n",
      "  [ 68  66  41]\n",
      "  [ 55  63  42]]\n",
      "\n",
      " [[  0  32  50]\n",
      "  [ 42 101 135]\n",
      "  [121 217 239]\n",
      "  ..., \n",
      "  [ 87  80  52]\n",
      "  [ 70  68  43]\n",
      "  [ 58  66  46]]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "images_array = np.array(images)\n",
    "labels_array = np.array(labels)\n",
    "\n",
    "# Print the `images` dimensions\n",
    "print(images_array.ndim)\n",
    "\n",
    "# # Print the number of `images`'s elements\n",
    "print(images_array.size)\n",
    "\n",
    "# # Print the first instance of `images`\n",
    "print(images_array[0])\n",
    "\n",
    "# # Print the `labels` dimensions\n",
    "print(labels_array.ndim)\n",
    "\n",
    "# # Print the number of `labels`'s elements\n",
    "# print(labels_array.size)\n",
    "\n",
    "# # Count the number of labels\n",
    "# print(len(set(labels_array)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the `pyplot` module\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Make a histogram with 62 bins of the `labels` data\n",
    "plt.hist(labels, 62)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the `pyplot` module of `matplotlib`\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Determine the (random) indexes of the images that you want to see \n",
    "traffic_signs = [300, 2250, 3650, 4000]\n",
    "\n",
    "# Fill out the subplots with the random images that you defined \n",
    "for i in range(len(traffic_signs)):\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[traffic_signs[i]])\n",
    "    plt.subplots_adjust(wspace=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (62, 61, 3), min: 3, max: 160\n",
      "shape: (110, 96, 3), min: 3, max: 255\n",
      "shape: (379, 153, 3), min: 0, max: 255\n",
      "shape: (100, 68, 3), min: 17, max: 255\n"
     ]
    }
   ],
   "source": [
    "# Import `matplotlib`\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Determine the (random) indexes of the images\n",
    "traffic_signs = [300, 2250, 3650, 4000]\n",
    "\n",
    "# Fill out the subplots with the random images and add shape, min and max values\n",
    "for i in range(len(traffic_signs)):\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[traffic_signs[i]])\n",
    "    plt.subplots_adjust(wspace=0.5)\n",
    "    plt.show()\n",
    "    print(\"shape: {0}, min: {1}, max: {2}\".format(images[traffic_signs[i]].shape, \n",
    "                                                  images[traffic_signs[i]].min(), \n",
    "                                                  images[traffic_signs[i]].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the `pyplot` module as `plt`\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Get the unique labels \n",
    "unique_labels = set(labels)\n",
    "\n",
    "# Initialize the figure\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "# Set a counter\n",
    "i = 1\n",
    "\n",
    "# For each unique label,\n",
    "for label in unique_labels:\n",
    "    # You pick the first image for each label\n",
    "    image = images[labels.index(label)]\n",
    "    # Define 64 subplots \n",
    "    plt.subplot(8, 8, i)\n",
    "    # Don't include axes\n",
    "    plt.axis('off')\n",
    "    # Add a title to each subplot \n",
    "    plt.title(\"Label {0} ({1})\".format(label, labels.count(label)))\n",
    "    # Add 1 to the counter\n",
    "    i += 1\n",
    "    # And you plot this first image \n",
    "    plt.imshow(image)\n",
    "    \n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='extraction'></a>\n",
    "## Feature Extraction\n",
    "### Rescaling Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "# Resize images\n",
    "images32 = [transform.resize(image, (28, 28)) for image in images]\n",
    "images32 = np.array(images32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (28, 28, 3), min: 0.06176470588235303, max: 0.6161764705882353\n",
      "shape: (28, 28, 3), min: 0.07634053621448567, max: 1.0\n",
      "shape: (28, 28, 3), min: 0.08464760904361854, max: 1.0\n",
      "shape: (28, 28, 3), min: 0.08907563025210075, max: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Import `matplotlib`\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Determine the (random) indexes of the images\n",
    "traffic_signs = [300, 2250, 3650, 4000]\n",
    "\n",
    "# Fill out the subplots with the random images and add shape, min and max values\n",
    "for i in range(len(traffic_signs)):\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images32[traffic_signs[i]])\n",
    "    plt.subplots_adjust(wspace=0.5)\n",
    "    plt.show()\n",
    "    print(\"shape: {0}, min: {1}, max: {2}\".format(images32[traffic_signs[i]].shape, \n",
    "                                                  images32[traffic_signs[i]].min(), \n",
    "                                                  images32[traffic_signs[i]].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Conversion to Grayscale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images32 = rgb2gray(np.array(images32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4575, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(traffic_signs)):\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images32[traffic_signs[i]], cmap=\"gray\")\n",
    "    plt.subplots_adjust(wspace=0.5)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "print(images32.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.74229485,  0.42599509,  0.40878256,  0.4202495 ,  0.41755521,\n",
       "         0.48030214,  0.44963976,  0.44602086,  0.47556737,  0.49706019,\n",
       "         0.50588577,  0.64844137,  0.77811458,  0.70713649,  0.48676711,\n",
       "         0.26363427,  0.16729424,  0.32515452,  0.24029734,  0.28989687,\n",
       "         0.34697073,  0.31421003,  0.22842276,  0.23414764,  0.22509232,\n",
       "         0.23291985,  0.20067085,  0.19750793],\n",
       "       [ 0.60493667,  0.29537234,  0.29832879,  0.29311906,  0.31078613,\n",
       "         0.2729798 ,  0.30964014,  0.30606758,  0.2903363 ,  0.29848809,\n",
       "         0.36972654,  0.39749475,  0.45374504,  0.45488612,  0.37049333,\n",
       "         0.18979712,  0.12247736,  0.34897782,  0.22131355,  0.34215979,\n",
       "         0.32304122,  0.28913361,  0.25752215,  0.21609345,  0.19518954,\n",
       "         0.21736126,  0.21597678,  0.22483184],\n",
       "       [ 0.58464503,  0.42008009,  0.39497093,  0.39232147,  0.42208728,\n",
       "         0.38122218,  0.44129249,  0.44515486,  0.40337708,  0.44775028,\n",
       "         0.60542391,  0.77113115,  0.72724508,  0.19550694,  0.49441295,\n",
       "         0.24845426,  0.12977143,  0.31427059,  0.25795989,  0.31375262,\n",
       "         0.30737058,  0.29483936,  0.25911204,  0.22177856,  0.20446624,\n",
       "         0.19452281,  0.20801678,  0.21786738],\n",
       "       [ 0.60672073,  0.43391981,  0.42924933,  0.42211741,  0.41653246,\n",
       "         0.44576617,  0.44552302,  0.45574216,  0.43275308,  0.46877908,\n",
       "         0.30028647,  0.99409255,  0.24512888,  0.22857085,  0.2443308 ,\n",
       "         0.62282065,  0.13028772,  0.30484962,  0.30282495,  0.31870272,\n",
       "         0.32995235,  0.30528964,  0.24175278,  0.23278598,  0.19060877,\n",
       "         0.20612174,  0.18203892,  0.17976017],\n",
       "       [ 0.84803282,  0.96240042,  0.97618189,  0.97917843,  0.93051811,\n",
       "         0.97262378,  0.9789215 ,  0.97319131,  0.96619382,  0.96432181,\n",
       "         0.96956831,  0.51964323,  0.2319196 ,  0.22650853,  0.2266363 ,\n",
       "         0.31013086,  0.41954591,  0.31281585,  0.28128509,  0.33153191,\n",
       "         0.44875063,  0.91302638,  0.23869915,  0.21154652,  0.1654114 ,\n",
       "         0.2141946 ,  0.23421759,  0.23816482],\n",
       "       [ 0.91208666,  0.98846049,  0.98448976,  0.99678859,  0.95115968,\n",
       "         0.99276443,  0.98932088,  0.99663641,  0.99025865,  0.99009726,\n",
       "         0.98947346,  0.21747611,  0.21544013,  0.22670168,  0.2302368 ,\n",
       "         0.22108121,  0.55614241,  0.33478437,  0.29005827,  0.32603034,\n",
       "         0.51945272,  0.99002307,  0.20413464,  0.19164093,  0.18813048,\n",
       "         0.19921146,  0.2198489 ,  0.22684364],\n",
       "       [ 0.93591791,  0.91431633,  0.0917204 ,  0.96797371,  0.96130342,\n",
       "         0.98644408,  0.15965873,  0.82431183,  0.98969799,  0.99890845,\n",
       "         0.61078574,  0.2533311 ,  0.22938441,  0.97802971,  0.24422093,\n",
       "         0.21774682,  0.2293043 ,  0.62273197,  0.36423885,  0.33432856,\n",
       "         0.61942463,  0.99082298,  0.21725879,  0.21360626,  0.20476702,\n",
       "         0.1916869 ,  0.19452758,  0.20124548],\n",
       "       [ 0.92844403,  0.82597536,  0.11510964,  0.97394161,  0.94567295,\n",
       "         0.97785432,  0.1215437 ,  0.84996341,  0.9669447 ,  0.9964682 ,\n",
       "         0.2314148 ,  0.24660141,  0.34807329,  0.99257442,  0.78242644,\n",
       "         0.21863652,  0.22433852,  0.43050169,  0.36070962,  0.32458676,\n",
       "         0.66021532,  0.88092437,  0.24099777,  0.22291211,  0.2132169 ,\n",
       "         0.21677729,  0.24510971,  0.23398195],\n",
       "       [ 0.3718845 ,  0.35787756,  0.32273009,  0.32921642,  0.36572808,\n",
       "         0.33568352,  0.32460295,  0.34916701,  0.65279135,  0.66543435,\n",
       "         0.24452166,  0.22968699,  0.96413624,  0.99124613,  0.99600865,\n",
       "         0.28021478,  0.23674226,  0.21610049,  0.65100799,  0.26643859,\n",
       "         0.47381245,  0.42723073,  0.19012033,  0.21249128,  0.21839094,\n",
       "         0.26775243,  0.24696859,  0.19898792],\n",
       "       [ 0.31138731,  0.30893559,  0.32351449,  0.35890827,  0.32894764,\n",
       "         0.35811344,  0.37673422,  0.36643933,  0.98089636,  0.24177717,\n",
       "         0.25126581,  0.31836445,  0.9910451 ,  0.9924145 ,  0.9941821 ,\n",
       "         0.91063392,  0.22660608,  0.23067155,  0.29221495,  0.47768644,\n",
       "         0.27359958,  0.25792635,  0.20578751,  0.23358084,  0.22221342,\n",
       "         0.22830762,  0.23794825,  0.23749861],\n",
       "       [ 0.27437223,  0.31572457,  0.32844415,  0.36204124,  0.35139513,\n",
       "         0.32586846,  0.36505618,  0.60694181,  0.79377909,  0.24754943,\n",
       "         0.24132104,  0.92833094,  0.99789467,  0.99787873,  0.99653975,\n",
       "         0.99546835,  0.52033924,  0.23486701,  0.22493582,  0.55794824,\n",
       "         0.28982724,  0.28060808,  0.22424247,  0.24885269,  0.22800631,\n",
       "         0.21165432,  0.18327744,  0.16382244],\n",
       "       [ 0.17058215,  0.16581085,  0.19587882,  0.19495758,  0.23298726,\n",
       "         0.24479466,  0.26496016,  0.93637229,  0.24563812,  0.24471887,\n",
       "         0.32471138,  0.99009364,  0.99511463,  0.99404265,  0.99657144,\n",
       "         0.99406256,  0.98288412,  0.23858288,  0.23106981,  0.25097266,\n",
       "         0.58687699,  0.30317664,  0.23512559,  0.16636946,  0.211513  ,\n",
       "         0.17502651,  0.17375394,  0.19620935],\n",
       "       [ 0.14957252,  0.12874107,  0.16857815,  0.14509109,  0.14525829,\n",
       "         0.13555819,  0.30589763,  0.76031802,  0.239547  ,  0.24556802,\n",
       "         0.94345434,  0.99264775,  0.98784214,  0.99793792,  0.9991369 ,\n",
       "         0.99347206,  0.99670274,  0.71307032,  0.24395499,  0.23560404,\n",
       "         0.44395354,  0.30254885,  0.21868833,  0.20213261,  0.22030721,\n",
       "         0.20550847,  0.2053294 ,  0.20560255],\n",
       "       [ 0.10589108,  0.11660183,  0.14278779,  0.11503575,  0.108842  ,\n",
       "         0.11064485,  0.96719226,  0.26047228,  0.23785111,  0.30749143,\n",
       "         0.99183262,  0.99264881,  0.99122693,  0.99525642,  0.99482307,\n",
       "         0.99574405,  0.99806425,  0.9988875 ,  0.30758346,  0.23023919,\n",
       "         0.23038318,  0.58377256,  0.16318493,  0.23639999,  0.20006004,\n",
       "         0.19814223,  0.25401464,  0.21198371],\n",
       "       [ 0.12022218,  0.09579308,  0.12636883,  0.12863911,  0.13189321,\n",
       "         0.29097378,  0.87284034,  0.22723814,  0.22880401,  0.87975978,\n",
       "         0.99524964,  0.98744661,  0.99017778,  0.99067251,  0.99702291,\n",
       "         0.9931835 ,  0.99695783,  0.99729471,  0.89352317,  0.23614107,\n",
       "         0.23546919,  0.35087087,  0.31152089,  0.16836657,  0.16424427,\n",
       "         0.1811337 ,  0.17974307,  0.19431878],\n",
       "       [ 0.12455655,  0.13950661,  0.10859849,  0.1414207 ,  0.11591495,\n",
       "         0.86710282,  0.25322544,  0.22535313,  0.28145285,  0.98487395,\n",
       "         0.99316964,  0.98964131,  0.99407738,  0.98732549,  0.99679664,\n",
       "         0.99160666,  0.99787202,  0.99537202,  0.99449612,  0.42676211,\n",
       "         0.22649166,  0.22197713,  0.57743262,  0.194355  ,  0.18441426,\n",
       "         0.18040103,  0.17750922,  0.19956691],\n",
       "       [ 0.11436039,  0.12097908,  0.10040742,  0.13028623,  0.18410044,\n",
       "         0.84017331,  0.23079396,  0.22900233,  0.87526806,  0.98967828,\n",
       "         0.99398284,  0.9888147 ,  0.99254853,  0.99462798,  0.99524185,\n",
       "         0.99172977,  0.98975716,  0.99442692,  0.9955171 ,  0.98094606,\n",
       "         0.22563084,  0.2343047 ,  0.274773  ,  0.48675443,  0.21709063,\n",
       "         0.18017603,  0.20727279,  0.20526972],\n",
       "       [ 0.12554775,  0.12718944,  0.09821557,  0.06915888,  0.94766446,\n",
       "         0.24989086,  0.22102864,  0.26532722,  0.98327547,  0.99355392,\n",
       "         0.98921483,  0.98607865,  0.99632273,  0.99749306,  0.9955654 ,\n",
       "         0.99938352,  0.88972891,  0.75386347,  0.97084985,  0.98747712,\n",
       "         0.64971422,  0.23401616,  0.23382555,  0.46830905,  0.21461184,\n",
       "         0.19315812,  0.21407602,  0.20132677],\n",
       "       [ 0.11715148,  0.10916609,  0.1187926 ,  0.2285271 ,  0.91601952,\n",
       "         0.23121519,  0.22189094,  0.80478637,  0.99524606,  0.9960582 ,\n",
       "         0.14332759,  0.23156232,  0.92710472,  0.99518781,  0.99369218,\n",
       "         0.69754756,  0.07512248,  0.06432515,  0.48781161,  0.98811128,\n",
       "         0.9913978 ,  0.26096072,  0.22023804,  0.22976365,  0.55403493,\n",
       "         0.25192186,  0.27492376,  0.22486045],\n",
       "       [ 0.11526044,  0.08238499,  0.07890523,  0.83764977,  0.25731299,\n",
       "         0.22477944,  0.26618535,  0.98410599,  0.98922247,  0.26477961,\n",
       "         0.05697643,  0.05996156,  0.30192856,  0.96254017,  0.96880649,\n",
       "         0.06151803,  0.05895128,  0.06377333,  0.1141844 ,  0.96843852,\n",
       "         0.98869257,  0.83108476,  0.22112628,  0.22081849,  0.37565113,\n",
       "         0.24709552,  0.20456969,  0.20688796],\n",
       "       [ 0.11236535,  0.08277252,  0.15504353,  0.90559928,  0.22344403,\n",
       "         0.21840961,  0.80968659,  0.98315275,  0.98402885,  0.05350608,\n",
       "         0.05865758,  0.07128401,  0.07349934,  0.04806278,  0.04240182,\n",
       "         0.05509841,  0.07382306,  0.14339153,  0.3653178 ,  0.98255422,\n",
       "         0.98502985,  0.97979113,  0.35660367,  0.22261813,  0.22626493,\n",
       "         0.58574923,  0.21436306,  0.20341448],\n",
       "       [ 0.14079473,  0.10391113,  0.8876266 ,  0.27116406,  0.23097858,\n",
       "         0.24606375,  0.97720081,  0.98704056,  0.98767055,  0.42017196,\n",
       "         0.72751463,  0.89988912,  0.97570483,  0.99201054,  0.9858701 ,\n",
       "         0.9930515 ,  0.97950226,  0.87540113,  0.63371431,  0.41288874,\n",
       "         0.27204916,  0.20573205,  0.23660721,  0.23279732,  0.22959371,\n",
       "         0.34082509,  0.22087477,  0.20551022],\n",
       "       [ 0.14084598,  0.12082418,  0.94775494,  0.22489768,  0.2226749 ,\n",
       "         0.68872593,  0.94655029,  0.83572949,  0.67189878,  0.46247777,\n",
       "         0.33966508,  0.27993605,  0.24678046,  0.22857353,  0.23686729,\n",
       "         0.2461609 ,  0.25741094,  0.22811944,  0.22822659,  0.22820835,\n",
       "         0.23281016,  0.23393352,  0.24687113,  0.23315686,  0.22779718,\n",
       "         0.53762036,  0.18416382,  0.190872  ],\n",
       "       [ 0.11911074,  0.3832837 ,  0.21606603,  0.21647213,  0.22530346,\n",
       "         0.21963906,  0.21457955,  0.22039617,  0.23575966,  0.22880709,\n",
       "         0.23581199,  0.2280052 ,  0.24183938,  0.2377929 ,  0.23999512,\n",
       "         0.23143041,  0.21574982,  0.21489705,  0.19424815,  0.21857333,\n",
       "         0.21373149,  0.26576058,  0.38906496,  0.66913462,  0.80294282,\n",
       "         0.2213153 ,  0.20429207,  0.2417473 ],\n",
       "       [ 0.11308155,  0.24841711,  0.2136556 ,  0.21208523,  0.21858255,\n",
       "         0.21311609,  0.21367544,  0.21739159,  0.20902245,  0.22321578,\n",
       "         0.22870227,  0.23903491,  0.39277964,  0.49061724,  0.78048292,\n",
       "         0.9080302 ,  0.73517148,  0.52851525,  0.27878582,  0.1683698 ,\n",
       "         0.10260299,  0.22532423,  0.36379028,  0.74824908,  0.93290471,\n",
       "         0.83312476,  0.33214926,  0.26035431],\n",
       "       [ 0.12344783,  0.07835322,  0.23837501,  0.26800891,  0.47531081,\n",
       "         0.70545371,  0.75689263,  0.52285368,  0.35713864,  0.15822008,\n",
       "         0.14038214,  0.08246192,  0.20531054,  0.40564545,  0.74051292,\n",
       "         0.87703251,  0.89917754,  0.62293213,  0.38348556,  0.24447192,\n",
       "         0.22418476,  0.1936184 ,  0.19378688,  0.20653663,  0.20990045,\n",
       "         0.21454492,  0.37697053,  0.26045292],\n",
       "       [ 0.10626822,  0.11566739,  0.54457578,  0.77197857,  0.87995392,\n",
       "         0.86270669,  0.73319887,  0.52350738,  0.31979043,  0.26015592,\n",
       "         0.23067498,  0.21473542,  0.20518284,  0.28406552,  0.18602636,\n",
       "         0.22552158,  0.21437462,  0.21000897,  0.2059518 ,  0.21415579,\n",
       "         0.21515626,  0.21322297,  0.21386326,  0.20962322,  0.21801777,\n",
       "         0.21074115,  0.26676441,  0.33422408],\n",
       "       [ 0.50224427,  0.74259682,  0.18700712,  0.19147151,  0.18956829,\n",
       "         0.20763259,  0.66990293,  0.95160337,  0.96477362,  0.7543478 ,\n",
       "         0.19980046,  0.39015681,  0.98637206,  0.94231331,  0.96065642,\n",
       "         0.203488  ,  0.19962292,  0.19727615,  0.19325923,  0.19978482,\n",
       "         0.24899768,  0.20965277,  0.21397044,  0.2029933 ,  0.21328991,\n",
       "         0.1961805 ,  0.2650083 ,  0.30369072]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images32[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dl'></a>\n",
    "## Deep Learning with Tensorflow\n",
    "\n",
    "### Modeling The Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images_flat:  Tensor(\"Flatten_2/flatten/Reshape:0\", shape=(?, 784), dtype=float32)\n",
      "logits:  Tensor(\"fully_connected_2/Relu:0\", shape=(?, 62), dtype=float32)\n",
      "loss:  Tensor(\"Mean_4:0\", shape=(), dtype=float32)\n",
      "predicted_labels:  Tensor(\"ArgMax_2:0\", shape=(?,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(dtype = tf.float32, shape = [None, 28, 28])\n",
    "y = tf.placeholder(dtype = tf.int32, shape = [None])\n",
    "images_flat = tf.contrib.layers.flatten(x)\n",
    "logits = tf.contrib.layers.fully_connected(images_flat, 62, tf.nn.relu)\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits = logits))\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "correct_pred = tf.argmax(logits, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "print(\"images_flat: \", images_flat)\n",
    "print(\"logits: \", logits)\n",
    "print(\"loss: \", loss)\n",
    "print(\"predicted_labels: \", correct_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running The Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "Loss:  Tensor(\"Mean_4:0\", shape=(), dtype=float32)\n",
      "DONE WITH EPOCH\n",
      "EPOCH 1\n",
      "DONE WITH EPOCH\n",
      "EPOCH 2\n",
      "DONE WITH EPOCH\n",
      "EPOCH 3\n",
      "DONE WITH EPOCH\n",
      "EPOCH 4\n",
      "DONE WITH EPOCH\n",
      "EPOCH 5\n",
      "DONE WITH EPOCH\n",
      "EPOCH 6\n",
      "DONE WITH EPOCH\n",
      "EPOCH 7\n",
      "DONE WITH EPOCH\n",
      "EPOCH 8\n",
      "DONE WITH EPOCH\n",
      "EPOCH 9\n",
      "DONE WITH EPOCH\n",
      "EPOCH 10\n",
      "Loss:  Tensor(\"Mean_4:0\", shape=(), dtype=float32)\n",
      "DONE WITH EPOCH\n",
      "EPOCH 11\n",
      "DONE WITH EPOCH\n",
      "EPOCH 12\n",
      "DONE WITH EPOCH\n",
      "EPOCH 13\n",
      "DONE WITH EPOCH\n",
      "EPOCH 14\n",
      "DONE WITH EPOCH\n",
      "EPOCH 15\n",
      "DONE WITH EPOCH\n",
      "EPOCH 16\n",
      "DONE WITH EPOCH\n",
      "EPOCH 17\n",
      "DONE WITH EPOCH\n",
      "EPOCH 18\n",
      "DONE WITH EPOCH\n",
      "EPOCH 19\n",
      "DONE WITH EPOCH\n",
      "EPOCH 20\n",
      "Loss:  Tensor(\"Mean_4:0\", shape=(), dtype=float32)\n",
      "DONE WITH EPOCH\n",
      "EPOCH 21\n",
      "DONE WITH EPOCH\n",
      "EPOCH 22\n",
      "DONE WITH EPOCH\n",
      "EPOCH 23\n",
      "DONE WITH EPOCH\n",
      "EPOCH 24\n",
      "DONE WITH EPOCH\n",
      "EPOCH 25\n",
      "DONE WITH EPOCH\n",
      "EPOCH 26\n",
      "DONE WITH EPOCH\n",
      "EPOCH 27\n",
      "DONE WITH EPOCH\n",
      "EPOCH 28\n",
      "DONE WITH EPOCH\n",
      "EPOCH 29\n",
      "DONE WITH EPOCH\n",
      "EPOCH 30\n",
      "Loss:  Tensor(\"Mean_4:0\", shape=(), dtype=float32)\n",
      "DONE WITH EPOCH\n",
      "EPOCH 31\n",
      "DONE WITH EPOCH\n",
      "EPOCH 32\n",
      "DONE WITH EPOCH\n",
      "EPOCH 33\n",
      "DONE WITH EPOCH\n",
      "EPOCH 34\n",
      "DONE WITH EPOCH\n",
      "EPOCH 35\n",
      "DONE WITH EPOCH\n",
      "EPOCH 36\n",
      "DONE WITH EPOCH\n",
      "EPOCH 37\n",
      "DONE WITH EPOCH\n",
      "EPOCH 38\n",
      "DONE WITH EPOCH\n",
      "EPOCH 39\n",
      "DONE WITH EPOCH\n",
      "EPOCH 40\n",
      "Loss:  Tensor(\"Mean_4:0\", shape=(), dtype=float32)\n",
      "DONE WITH EPOCH\n",
      "EPOCH 41\n",
      "DONE WITH EPOCH\n",
      "EPOCH 42\n",
      "DONE WITH EPOCH\n",
      "EPOCH 43\n",
      "DONE WITH EPOCH\n",
      "EPOCH 44\n",
      "DONE WITH EPOCH\n",
      "EPOCH 45\n",
      "DONE WITH EPOCH\n",
      "EPOCH 46\n",
      "DONE WITH EPOCH\n",
      "EPOCH 47\n",
      "DONE WITH EPOCH\n",
      "EPOCH 48\n",
      "DONE WITH EPOCH\n",
      "EPOCH 49\n",
      "DONE WITH EPOCH\n",
      "EPOCH 50\n",
      "Loss:  Tensor(\"Mean_4:0\", shape=(), dtype=float32)\n",
      "DONE WITH EPOCH\n",
      "EPOCH 51\n",
      "DONE WITH EPOCH\n",
      "EPOCH 52\n",
      "DONE WITH EPOCH\n",
      "EPOCH 53\n",
      "DONE WITH EPOCH\n",
      "EPOCH 54\n",
      "DONE WITH EPOCH\n",
      "EPOCH 55\n",
      "DONE WITH EPOCH\n",
      "EPOCH 56\n",
      "DONE WITH EPOCH\n",
      "EPOCH 57\n",
      "DONE WITH EPOCH\n",
      "EPOCH 58\n",
      "DONE WITH EPOCH\n",
      "EPOCH 59\n",
      "DONE WITH EPOCH\n",
      "EPOCH 60\n",
      "Loss:  Tensor(\"Mean_4:0\", shape=(), dtype=float32)\n",
      "DONE WITH EPOCH\n",
      "EPOCH 61\n",
      "DONE WITH EPOCH\n",
      "EPOCH 62\n",
      "DONE WITH EPOCH\n",
      "EPOCH 63\n",
      "DONE WITH EPOCH\n",
      "EPOCH 64\n",
      "DONE WITH EPOCH\n",
      "EPOCH 65\n",
      "DONE WITH EPOCH\n",
      "EPOCH 66\n",
      "DONE WITH EPOCH\n",
      "EPOCH 67\n",
      "DONE WITH EPOCH\n",
      "EPOCH 68\n",
      "DONE WITH EPOCH\n",
      "EPOCH 69\n",
      "DONE WITH EPOCH\n",
      "EPOCH 70\n",
      "Loss:  Tensor(\"Mean_4:0\", shape=(), dtype=float32)\n",
      "DONE WITH EPOCH\n",
      "EPOCH 71\n",
      "DONE WITH EPOCH\n",
      "EPOCH 72\n",
      "DONE WITH EPOCH\n",
      "EPOCH 73\n",
      "DONE WITH EPOCH\n",
      "EPOCH 74\n",
      "DONE WITH EPOCH\n",
      "EPOCH 75\n",
      "DONE WITH EPOCH\n",
      "EPOCH 76\n",
      "DONE WITH EPOCH\n",
      "EPOCH 77\n",
      "DONE WITH EPOCH\n",
      "EPOCH 78\n",
      "DONE WITH EPOCH\n",
      "EPOCH 79\n",
      "DONE WITH EPOCH\n",
      "EPOCH 80\n",
      "Loss:  Tensor(\"Mean_4:0\", shape=(), dtype=float32)\n",
      "DONE WITH EPOCH\n",
      "EPOCH 81\n",
      "DONE WITH EPOCH\n",
      "EPOCH 82\n",
      "DONE WITH EPOCH\n",
      "EPOCH 83\n",
      "DONE WITH EPOCH\n",
      "EPOCH 84\n",
      "DONE WITH EPOCH\n",
      "EPOCH 85\n",
      "DONE WITH EPOCH\n",
      "EPOCH 86\n",
      "DONE WITH EPOCH\n",
      "EPOCH 87\n",
      "DONE WITH EPOCH\n",
      "EPOCH 88\n",
      "DONE WITH EPOCH\n",
      "EPOCH 89\n",
      "DONE WITH EPOCH\n",
      "EPOCH 90\n",
      "Loss:  Tensor(\"Mean_4:0\", shape=(), dtype=float32)\n",
      "DONE WITH EPOCH\n",
      "EPOCH 91\n",
      "DONE WITH EPOCH\n",
      "EPOCH 92\n",
      "DONE WITH EPOCH\n",
      "EPOCH 93\n",
      "DONE WITH EPOCH\n",
      "EPOCH 94\n",
      "DONE WITH EPOCH\n",
      "EPOCH 95\n",
      "DONE WITH EPOCH\n",
      "EPOCH 96\n",
      "DONE WITH EPOCH\n",
      "EPOCH 97\n",
      "DONE WITH EPOCH\n",
      "EPOCH 98\n",
      "DONE WITH EPOCH\n",
      "EPOCH 99\n",
      "DONE WITH EPOCH\n",
      "EPOCH 100\n",
      "Loss:  Tensor(\"Mean_4:0\", shape=(), dtype=float32)\n",
      "DONE WITH EPOCH\n",
      "EPOCH 101\n",
      "DONE WITH EPOCH\n",
      "EPOCH 102\n",
      "DONE WITH EPOCH\n",
      "EPOCH 103\n",
      "DONE WITH EPOCH\n",
      "EPOCH 104\n",
      "DONE WITH EPOCH\n",
      "EPOCH 105\n",
      "DONE WITH EPOCH\n",
      "EPOCH 106\n",
      "DONE WITH EPOCH\n",
      "EPOCH 107\n",
      "DONE WITH EPOCH\n",
      "EPOCH 108\n",
      "DONE WITH EPOCH\n",
      "EPOCH 109\n",
      "DONE WITH EPOCH\n",
      "EPOCH 110\n",
      "Loss:  Tensor(\"Mean_4:0\", shape=(), dtype=float32)\n",
      "DONE WITH EPOCH\n",
      "EPOCH 111\n",
      "DONE WITH EPOCH\n",
      "EPOCH 112\n",
      "DONE WITH EPOCH\n",
      "EPOCH 113\n",
      "DONE WITH EPOCH\n",
      "EPOCH 114\n",
      "DONE WITH EPOCH\n",
      "EPOCH 115\n",
      "DONE WITH EPOCH\n",
      "EPOCH 116\n",
      "DONE WITH EPOCH\n",
      "EPOCH 117\n",
      "DONE WITH EPOCH\n",
      "EPOCH 118\n",
      "DONE WITH EPOCH\n",
      "EPOCH 119\n",
      "DONE WITH EPOCH\n",
      "EPOCH 120\n",
      "Loss:  Tensor(\"Mean_4:0\", shape=(), dtype=float32)\n",
      "DONE WITH EPOCH\n",
      "EPOCH 121\n",
      "DONE WITH EPOCH\n",
      "EPOCH 122\n",
      "DONE WITH EPOCH\n",
      "EPOCH 123\n",
      "DONE WITH EPOCH\n",
      "EPOCH 124\n",
      "DONE WITH EPOCH\n",
      "EPOCH 125\n",
      "DONE WITH EPOCH\n",
      "EPOCH 126\n",
      "DONE WITH EPOCH\n",
      "EPOCH 127\n",
      "DONE WITH EPOCH\n",
      "EPOCH 128\n",
      "DONE WITH EPOCH\n",
      "EPOCH 129\n",
      "DONE WITH EPOCH\n",
      "EPOCH 130\n",
      "Loss:  Tensor(\"Mean_4:0\", shape=(), dtype=float32)\n",
      "DONE WITH EPOCH\n",
      "EPOCH 131\n",
      "DONE WITH EPOCH\n",
      "EPOCH 132\n",
      "DONE WITH EPOCH\n",
      "EPOCH 133\n",
      "DONE WITH EPOCH\n",
      "EPOCH 134\n",
      "DONE WITH EPOCH\n",
      "EPOCH 135\n",
      "DONE WITH EPOCH\n",
      "EPOCH 136\n",
      "DONE WITH EPOCH\n",
      "EPOCH 137\n",
      "DONE WITH EPOCH\n",
      "EPOCH 138\n",
      "DONE WITH EPOCH\n",
      "EPOCH 139\n",
      "DONE WITH EPOCH\n",
      "EPOCH 140\n",
      "Loss:  Tensor(\"Mean_4:0\", shape=(), dtype=float32)\n",
      "DONE WITH EPOCH\n",
      "EPOCH 141\n",
      "DONE WITH EPOCH\n",
      "EPOCH 142\n",
      "DONE WITH EPOCH\n",
      "EPOCH 143\n",
      "DONE WITH EPOCH\n",
      "EPOCH 144\n",
      "DONE WITH EPOCH\n",
      "EPOCH 145\n",
      "DONE WITH EPOCH\n",
      "EPOCH 146\n",
      "DONE WITH EPOCH\n",
      "EPOCH 147\n",
      "DONE WITH EPOCH\n",
      "EPOCH 148\n",
      "DONE WITH EPOCH\n",
      "EPOCH 149\n",
      "DONE WITH EPOCH\n",
      "EPOCH 150\n",
      "Loss:  Tensor(\"Mean_4:0\", shape=(), dtype=float32)\n",
      "DONE WITH EPOCH\n",
      "EPOCH 151\n",
      "DONE WITH EPOCH\n",
      "EPOCH 152\n",
      "DONE WITH EPOCH\n",
      "EPOCH 153\n",
      "DONE WITH EPOCH\n",
      "EPOCH 154\n",
      "DONE WITH EPOCH\n",
      "EPOCH 155\n",
      "DONE WITH EPOCH\n",
      "EPOCH 156\n",
      "DONE WITH EPOCH\n",
      "EPOCH 157\n",
      "DONE WITH EPOCH\n",
      "EPOCH 158\n",
      "DONE WITH EPOCH\n",
      "EPOCH 159\n",
      "DONE WITH EPOCH\n",
      "EPOCH 160\n",
      "Loss:  Tensor(\"Mean_4:0\", shape=(), dtype=float32)\n",
      "DONE WITH EPOCH\n",
      "EPOCH 161\n",
      "DONE WITH EPOCH\n",
      "EPOCH 162\n",
      "DONE WITH EPOCH\n",
      "EPOCH 163\n",
      "DONE WITH EPOCH\n",
      "EPOCH 164\n",
      "DONE WITH EPOCH\n",
      "EPOCH 165\n",
      "DONE WITH EPOCH\n",
      "EPOCH 166\n",
      "DONE WITH EPOCH\n",
      "EPOCH 167\n",
      "DONE WITH EPOCH\n",
      "EPOCH 168\n",
      "DONE WITH EPOCH\n",
      "EPOCH 169\n",
      "DONE WITH EPOCH\n",
      "EPOCH 170\n",
      "Loss:  Tensor(\"Mean_4:0\", shape=(), dtype=float32)\n",
      "DONE WITH EPOCH\n",
      "EPOCH 171\n",
      "DONE WITH EPOCH\n",
      "EPOCH 172\n",
      "DONE WITH EPOCH\n",
      "EPOCH 173\n",
      "DONE WITH EPOCH\n",
      "EPOCH 174\n",
      "DONE WITH EPOCH\n",
      "EPOCH 175\n",
      "DONE WITH EPOCH\n",
      "EPOCH 176\n",
      "DONE WITH EPOCH\n",
      "EPOCH 177\n",
      "DONE WITH EPOCH\n",
      "EPOCH 178\n",
      "DONE WITH EPOCH\n",
      "EPOCH 179\n",
      "DONE WITH EPOCH\n",
      "EPOCH 180\n",
      "Loss:  Tensor(\"Mean_4:0\", shape=(), dtype=float32)\n",
      "DONE WITH EPOCH\n",
      "EPOCH 181\n",
      "DONE WITH EPOCH\n",
      "EPOCH 182\n",
      "DONE WITH EPOCH\n",
      "EPOCH 183\n",
      "DONE WITH EPOCH\n",
      "EPOCH 184\n",
      "DONE WITH EPOCH\n",
      "EPOCH 185\n",
      "DONE WITH EPOCH\n",
      "EPOCH 186\n",
      "DONE WITH EPOCH\n",
      "EPOCH 187\n",
      "DONE WITH EPOCH\n",
      "EPOCH 188\n",
      "DONE WITH EPOCH\n",
      "EPOCH 189\n",
      "DONE WITH EPOCH\n",
      "EPOCH 190\n",
      "Loss:  Tensor(\"Mean_4:0\", shape=(), dtype=float32)\n",
      "DONE WITH EPOCH\n",
      "EPOCH 191\n",
      "DONE WITH EPOCH\n",
      "EPOCH 192\n",
      "DONE WITH EPOCH\n",
      "EPOCH 193\n",
      "DONE WITH EPOCH\n",
      "EPOCH 194\n",
      "DONE WITH EPOCH\n",
      "EPOCH 195\n",
      "DONE WITH EPOCH\n",
      "EPOCH 196\n",
      "DONE WITH EPOCH\n",
      "EPOCH 197\n",
      "DONE WITH EPOCH\n",
      "EPOCH 198\n",
      "DONE WITH EPOCH\n",
      "EPOCH 199\n",
      "DONE WITH EPOCH\n",
      "EPOCH 200\n",
      "Loss:  Tensor(\"Mean_4:0\", shape=(), dtype=float32)\n",
      "DONE WITH EPOCH\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(201):\n",
    "        print('EPOCH', i)\n",
    "        _, accuracy_val = sess.run([train_op, accuracy], feed_dict={x: images32, y: labels})\n",
    "        if i % 10 == 0:\n",
    "            print(\"Loss: \", loss)\n",
    "        print('DONE WITH EPOCH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alternatively, you can also run the following lines of code instead of the code chunk above:\n",
    "#with tf.Session() as sess:\n",
    "#    sess.run(tf.global_variables_initializer())\n",
    "#    for i in range(201):\n",
    "#        print('EPOCH', i)\n",
    "#        _, accuracy_val = sess.run([train_op, accuracy], feed_dict={x: images32, y: labels})\n",
    "#        if i % 10 == 0:\n",
    "#            print(\"Loss: \", loss)\n",
    "#        print('DONE WITH EPOCH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating The Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick 10 random images\n",
    "sample_indexes = random.sample(range(len(images32)), 10)\n",
    "sample_images = [images32[i] for i in sample_indexes]\n",
    "sample_labels = [labels[i] for i in sample_indexes]\n",
    "\n",
    "# Run the \"predicted_labels\" op.\n",
    "predicted = sess.run([correct_pred], feed_dict={x: sample_images})[0]\n",
    "                        \n",
    "# Print the real and predicted labels\n",
    "print(sample_labels)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Display the predictions and the ground truth visually.\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "for i in range(len(sample_images)):\n",
    "    truth = sample_labels[i]\n",
    "    prediction = predicted[i]\n",
    "    plt.subplot(5, 2,1+i)\n",
    "    plt.axis('off')\n",
    "    color='green' if truth == prediction else 'red'\n",
    "    plt.text(40, 10, \"Truth:        {0}\\nPrediction: {1}\".format(truth, prediction), \n",
    "             fontsize=12, color=color)\n",
    "    plt.imshow(sample_images[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "# Load the test data\n",
    "test_images, test_labels = load_data(test_data_dir)\n",
    "\n",
    "# Transform the images to 28 by 28 pixels\n",
    "test_images28 = [transform.resize(image, (28, 28)) for image in test_images]\n",
    "\n",
    "# Convert to grayscale\n",
    "from skimage.color import rgb2gray\n",
    "test_images28 = rgb2gray(np.array(test_images28))\n",
    "\n",
    "# Run predictions against the full test set.\n",
    "predicted = sess.run([correct_pred], feed_dict={x: test_images28})[0]\n",
    "\n",
    "# Calculate correct matches \n",
    "match_count = sum([int(y == y_) for y, y_ in zip(test_labels, predicted)])\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = match_count / len(test_labels)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
