{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Squared Error\n",
    "$MSE(\\hat{w})=\\frac{1}{N}(y-\\hat{\\mathbf{w}}^T\\mathbf{x})^T(y-\\hat{\\mathbf{w}}^T\\mathbf{x})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_mse_vectorized(w,X,Y):\n",
    "    '''This function returns de MSE for a given dataset and coefficients'''\n",
    "    res = Y - np.dot(X,w)\n",
    "    totalError = np.dot(res.T,res)\n",
    "    return totalError / float(len(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão Multivariada Vetorizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step_gradient_vectorized(w_current,X,Y,alpha):\n",
    "    '''This function calculates the step gradient using alpha value as stepsize.'''\n",
    "    w = w_current\n",
    "    Y_pred = np.dot(X, w) #valores previstos com o vetor de coeficientes atual\n",
    "    res = np.subtract(Y,Y_pred) #resíduos entre Y observados e Y previstos\n",
    "    gradient_rss = -2*np.dot(X.T,res) #vetor de derivadas parciais  \n",
    "    new_w = np.subtract(w ,alpha*(gradient_rss))\n",
    "    return [new_w, gradient_rss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent_runner_vectorized(starting_w, X,Y, learning_rate, epsilon):\n",
    "    '''This function returns the coefficients' vector'''\n",
    "    w = starting_w\n",
    "    grad = np.array([np.inf,np.inf,np.inf,np.inf,np.inf])  \n",
    "    i = 0\n",
    "    while(np.linalg.norm(grad) >= epsilon):\n",
    "        w, grad = step_gradient_vectorized(w, X, Y, learning_rate)\n",
    "    #         if i % 1000 == 0:\n",
    "    #             print(\"MSE na iteração {0} é de {1}\".format(i,compute_mse_vectorized(w, X, Y)))\n",
    "    #             print(\"grad norm: {0}\".format(np.linalg.norm(grad)))\n",
    "    #         i+= 1\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.genfromtxt(\"../data/sample_treino.csv\", delimiter=\",\")\n",
    "points = points[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = points[:,[0,1,2,3,4]]\n",
    "Y = points[:,[5]]\n",
    "\n",
    "num_coeficients = X.shape[1]\n",
    "init_w = np.zeros((num_coeficients,1))\n",
    "\n",
    "learning_rate = 0.000001\n",
    "epsilon = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0378639698028564\n"
     ]
    }
   ],
   "source": [
    "start_grad_desc_runner_time = time.time()\n",
    "w = gradient_descent_runner_vectorized(init_w, X, Y, learning_rate, epsilon)\n",
    "end_grad_desc_runner_time = time.time()\n",
    "print(end_grad_desc_runner_time - start_grad_desc_runner_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [[ 0.13498004]\n",
      " [ 0.12815704]\n",
      " [ 0.16166461]\n",
      " [ 0.46477514]\n",
      " [ 0.04199859]]\n"
     ]
    }
   ],
   "source": [
    "# The coefficients\n",
    "print('Coefficients: \\n', w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão Ridge com sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0076520442962646484\n",
      "Coefficients: \n",
      " [[ 0.10304143]\n",
      " [ 0.0464367 ]\n",
      " [ 0.16409834]\n",
      " [ 0.38117842]\n",
      " [ 0.02027816]]\n"
     ]
    }
   ],
   "source": [
    "start_sklearn_reg = time.time()\n",
    "# Create linear regression object\n",
    "regr = linear_model.Ridge(alpha=learning_rate, tol=epsilon)\n",
    "# Train the model using the training sets\n",
    "regr.fit(X, Y)\n",
    "end_sklearn_reg = time.time()\n",
    "print(end_sklearn_reg - start_sklearn_reg)\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparando Coeficientes de Regressão Implementada vs SKLearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlação de w com regr.coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.       ,  0.9758408],\n",
       "       [ 0.9758408,  1.       ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(w.T, regr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como é possível observar, os dois vetores possuem alta correlação positiva (aprox. 0.976),\n",
    "indicando que ambos os vetores crescem na mesma proporção. Para analisar os resultados de forma mais precisa, será utilizado uma regressão linear afim de analisar o quão próximos foram os resultados de ambas as regressões criadas acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_regr = linear_model.LinearRegression()\n",
    "coef_regr.fit(w, regr.coef_.T)\n",
    "coef = coef_regr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b3a356885c7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Coeficientes da Regressão Implementada vs SKlearn Ridge'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'w' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(w.T, regr.coef_, 'ro')\n",
    "plt.axis([0, 0.5, 0, 0.5])\n",
    "plt.title('Coeficientes da Regressão Implementada vs SKlearn Ridge')\n",
    "x_sample = np.linspace(0,0.5)\n",
    "plt.plot(x_sample, x_sample*coef[0], '--', linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
