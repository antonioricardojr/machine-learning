{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Squared Error\n",
    "$MSE(\\hat{w})=\\frac{1}{N}(y-\\hat{\\mathbf{w}}^T\\mathbf{x})^T(y-\\hat{\\mathbf{w}}^T\\mathbf{x})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_mse_vectorized(w,X,Y):\n",
    "    '''This function returns de MSE for a given dataset and coefficients'''\n",
    "    res = Y - np.dot(X,w)\n",
    "    totalError = np.dot(res.T,res)\n",
    "    return totalError / float(len(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão Logística Vetorizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step_gradient_vectorized(w_current,X,Y,alpha):\n",
    "    '''This function calculates the step gradient using alpha value as stepsize.'''\n",
    "    w = w_current\n",
    "    Y_pred = np.dot(X, w) #valores previstos com o vetor de coeficientes atual\n",
    "    res = np.subtract(Y,Y_pred) #resíduos entre Y observados e Y previstos\n",
    "    gradient_rss = -2*np.dot(X.T,res) #vetor de derivadas parciais  \n",
    "    new_w = np.add(w ,alpha*(gradient_rss))\n",
    "    return [new_w, gradient_rss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_ascent_runner_vectorized(starting_w, X,Y, learning_rate, epsilon):\n",
    "    '''This function returns the coefficients' vector'''\n",
    "    w = starting_w\n",
    "    grad = np.array([np.inf,np.inf,np.inf,np.inf,np.inf])  \n",
    "    i = 0\n",
    "    while(np.linalg.norm(grad) >= epsilon):\n",
    "        w, grad = step_gradient_vectorized(w, X, Y, learning_rate)\n",
    "    #         if i % 1000 == 0:\n",
    "    #             print(\"MSE na iteração {0} é de {1}\".format(i,compute_mse_vectorized(w, X, Y)))\n",
    "    #             print(\"grad norm: {0}\".format(np.linalg.norm(grad)))\n",
    "    #         i+= 1\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.genfromtxt(\"../data/iris.csv\", delimiter=\",\", dtype=\"str\")\n",
    "points = points[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(Y):\n",
    "    '''It sets the classes's values to 0 or 1 integers'''\n",
    "    levels = np.unique(Y)\n",
    "    resp = np.where(Y == levels[0],0,1)\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = points[:,[0,1,2,3]].astype(\"float\")\n",
    "Y = predict(points[:,[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_coeficients = X.shape[1]\n",
    "init_w = np.zeros((num_coeficients,1))\n",
    "\n",
    "learning_rate = 0.001\n",
    "epsilon = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_grad_asc_runner_time = time.time()\n",
    "w = gradient_ascent_runner_vectorized(init_w, X, Y, learning_rate, epsilon)\n",
    "end_grad_asc_runner_time = time.time()\n",
    "print('time: {0}'.format(end_grad_asc_runner_time - start_grad_asc_runner_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The coefficients\n",
    "print('Coefficients: \\n', w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão com sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_sklearn_reg = time.time()\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "# Train the model using the training sets\n",
    "regr.fit(X, Y)\n",
    "end_sklearn_reg = time.time()\n",
    "print('time: {0}'.format(end_sklearn_reg - start_sklearn_reg))\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
